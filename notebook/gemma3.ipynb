{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb33ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxachin/Desktop/Codes/fundify-gemini/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "from groq import Groq\n",
    "import base64\n",
    "import os\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5555dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCCv1G_KtyBMf5jQMOm8CjMUIPM53WLG3U\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"GOOGLE_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8169f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.environ.get(\"GOOGLE_API\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4982a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46018ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [03:08<00:00, 11.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Store Pdf with convert_from_path function\n",
    "images = convert_from_path('../Zarnik Deck - PedalUp Demo Day_compressed.pdf')\n",
    "\n",
    "summ = []\n",
    "for i in tqdm(range(len(images))):\n",
    "  \n",
    "      # Save pages as images in the pdf\n",
    "    path = '../pdf_images/page'+ str(i) +'.jpg'\n",
    "    images[i].save(path, 'JPEG')\n",
    "\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemma-3-27b-it',\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "        data=base64_image,\n",
    "        mime_type='image/jpeg',\n",
    "        ),\n",
    "        'Describe this image.'\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    # print(response.text)\n",
    "    # response = ollama.chat(model='gemma3:latest', \n",
    "    #             messages=[{\n",
    "    #                 'role': 'user', \n",
    "    #                 'content': \"Detailed summary of this image, in terms of contents. if no content then just say no content, output should be just bullet points\",\n",
    "    #                 'images': [path]\n",
    "    #             }],\n",
    "    #             # options={\"temperature\":0.7}\n",
    "    #             )\n",
    "    #         # image_summaries.append(response.text)\n",
    "    summ.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9393a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ' '.join(summ)\n",
    "with open(\"zarnik_extract.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848b8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"zarnik_extract.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    doc = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1534b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33119/3424808334.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"../multilingual-e5-large-instruct\")\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = text_splitter.create_documents([doc])\n",
    "\n",
    "# 3. Set up embedding model (using Sentence Transformers)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"../multilingual-e5-large-instruct\")\n",
    "\n",
    "# 4. Store in ChromaDB\n",
    "db = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1726c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={'k': 10,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a90077",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = [\n",
    "    \"Problem Clarity\",\n",
    "    \"Solution Fit\",\n",
    "    \"Market Size & Insight\",\n",
    "    \"Business Model\",\n",
    "    \"Traction & Metrics\",\n",
    "    \"Team Composition\",\n",
    "    \"Competitive Advantage\",\n",
    "    \"Go-To-Market Plan\",\n",
    "    \"Financials & Ask\",\n",
    "    \"Storytelling & Design\"\n",
    "]\n",
    "\n",
    "section_wise_results = []\n",
    "\n",
    "for item in section:\n",
    "\n",
    "  query = f\"Give a score based on {item} (1-10)\"\n",
    "\n",
    "  retrieved_docs = retriever.get_relevant_documents(query,)\n",
    "  context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "  You are a helpful assistant. Given the following context retrieved from a document, answer the question below in JSON format. Provide a balanced evaluation based on the context. Ensure that each section is supported by information from the context.\n",
    "\n",
    "  Context:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {query}\n",
    "\n",
    "  Provide your answer in the following JSON format:\n",
    "  {{\n",
    "    \"Score\": \"<Provide an overall rating or evaluation (e.g., 1–10, or 'High', 'Medium', 'Low')>\",\n",
    "    \"Positive reasons\": \"<List the positive aspects or arguments from the context>\",\n",
    "    \"Negative reasons\": \"<List the negative aspects or counterpoints from the context>\"\n",
    "  }}\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.models.generate_content(\n",
    "    model=\"gemma-3-27b-it\",\n",
    "    contents=[prompt])\n",
    "\n",
    "  section_wise_results.append(response.text)\n",
    "# Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73def2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Score\": \"6\",\n",
      "  \"Positive reasons\": \"The context describes slides from a pitch deck that demonstrate a clear and professional visual style. The use of color-coding, readable fonts, and simple layouts contribute to effective communication of information. The slides cover key areas like problem identification, competitive landscape, and traction metrics, suggesting a thoughtful approach to business planning.\",\n",
      "  \"Negative reasons\": \"The provided context does *not* contain any information about the team composition itself. It only describes the visual presentation of slides related to market analysis and business strategy. Therefore, a score based on team composition is impossible to derive from the given information. The score is a moderate 6, reflecting the quality of the presentation materials, but acknowledging the complete absence of team-related data.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(section_wise_results[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead804c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
